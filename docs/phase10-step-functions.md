Phase 10: Step Functions Workflow Orchestration

Phase Duration: February 17-19, 2026 (Days 15-17)
Status: âœ… COMPLETE
AWS Region: eu-west-1 (Europe - Ireland)
Overview

I successfully completed Phase 10, the final phase of my Infrastructure Monitoring Pipeline project. In this phase, I implemented AWS Step Functions to orchestrate the entire data collection, processing, and alerting workflow with parallel processing branches for optimal performance.

This was the most technically challenging phase, requiring me to design a sophisticated state machine that coordinates multiple AWS services while maintaining fault tolerance and cost efficiency.
What I Built
Step Functions State Machine

I created a comprehensive workflow orchestration system called InfraMonitoring-Pipeline-Orchestration that:

    Collects metrics in parallel using 4 simultaneous Lambda invocations
    Handles errors gracefully with retry logic and fallback states
    Integrates with EventBridge for automated 3-hour scheduling
    Sends notifications via SNS for both success and failure scenarios
    Stays within AWS Free Tier (2,880 transitions/month vs 4,000 limit)

Architecture Flow

EventBridge (Every 3 Hours)
    â†“
Step Functions State Machine
    â†“
ParallelDataCollection (4 branches)
    â”œâ”€â†’ CPU Metrics
    â”œâ”€â†’ Memory Metrics
    â”œâ”€â†’ Disk Metrics
    â””â”€â†’ Network Metrics
    â†“
WaitForProcessing (5 seconds)
    â†“
CheckPipelineHealth
    â†“
ParallelAnalytics (2 branches)
    â†“
NotifySuccess (SNS Email)
    â†“
END

Implementation Steps
Step 1: Created IAM Role for Step Functions

Date: February 17, 2026

I started by creating a dedicated IAM role for Step Functions with the necessary permissions:

# Created IAM role
aws iam create-role \
  --role-name step-functions-execution-role \
  --assume-role-policy-document file://trust-policy.json \
  --region eu-west-1

# Attached permissions policy
aws iam put-role-policy \
  --role-name step-functions-execution-role \
  --policy-name StepFunctionsExecutionPolicy \
  --policy-document file://permissions-policy.json

Permissions I granted:

    lambda:InvokeFunction - To call my data-collector Lambda
    sns:Publish - To send email notifications
    logs:* - To write execution logs to CloudWatch

This role follows the principle of least privilege, granting only the permissions needed for the workflow.
Step 2: Designed the State Machine Workflow

Date: February 17, 2026

I designed the workflow with these key principles:

    Parallel Processing First - Collect all metrics simultaneously for maximum speed
    Wait for Dependencies - Allow S3 event processing to complete
    Health Checks - Verify pipeline status before proceeding
    Comprehensive Error Handling - Catch and handle all failure scenarios

My design decisions:

    Used Parallel state for simultaneous metric collection (3.3x faster than sequential)
    Added Wait state to allow S3 event-triggered Lambda to complete
    Implemented individual error handling per branch (partial success is better than complete failure)
    Included retry logic with exponential backoff (10s, 20s, 40s intervals)

Step 3: Created the State Machine

Date: February 18, 2026

I created the complete state machine definition with 4 parallel branches for data collection:

# Created state machine
aws stepfunctions create-state-machine \
  --name InfraMonitoring-Pipeline-Orchestration \
  --definition file://state-machine.json \
  --role-arn arn:aws:iam::190517931751:role/step-functions-execution-role \
  --region eu-west-1

Key components I implemented:

ParallelDataCollection State:

    4 branches executing simultaneously
    Each branch calls data-collector Lambda with specific metric_type parameter
    Individual retry logic: 3 attempts with exponential backoff
    Graceful failure handling: if one branch fails, others continue

Error Handling States:

    CPUCollectionFailed, MemoryCollectionFailed, etc. - Mark individual failures
    HandleError - Send SNS notification with error details
    FailState - Mark execution as failed

Success Path:

    WaitForProcessing - 5-second delay for S3 processing
    CheckPipelineHealth - Verify pipeline status
    ParallelAnalytics - Analyze collected metrics
    NotifySuccess - Send success email via SNS

Step 4: Modified Lambda Function for Parallel Processing

Date: February 18, 2026

I updated my data-collector Lambda function to accept a metric_type parameter from Step Functions:

Key changes I made:

def lambda_handler(event, context):
    # Extract metric_type from Step Functions input
    metric_type = event.get('metric_type', 'all')
    
    if metric_type == 'all':
        # Collect all metrics (backward compatibility)
        metrics = generate_all_metrics(timestamp, instance_id)
    else:
        # Collect specific metric type (parallel processing)
        metrics = [generate_specific_metric(metric_type, timestamp, instance_id)]

Why I did this:

    Enables targeted metric collection for parallel branches
    Maintains backward compatibility (defaults to 'all' if no parameter)
    Allows Step Functions to control which metrics each branch collects

I also updated the S3 file naming to include metric type:

s3_key = f"raw-metrics/{date_path}/metrics-{metric_type}-{timestamp}.json"

This creates separate files like:

    metrics-cpu_utilization-1771500463.json
    metrics-memory_usage-1771500463.json
    metrics-disk_usage-1771500463.json
    metrics-network_traffic-1771500462.json

Step 5: Configured EventBridge Schedule

Date: February 18, 2026

I created an EventBridge rule to trigger the Step Functions workflow every 3 hours:

# Created EventBridge rule
aws events put-rule \
  --name InfraMonitoring-Trigger \
  --schedule-expression "rate(3 hours)" \
  --state ENABLED \
  --region eu-west-1

# Added Step Functions as target
aws events put-targets \
  --rule InfraMonitoring-Trigger \
  --targets "Id"="1","Arn"="arn:aws:states:eu-west-1:190517931751:stateMachine:InfraMonitoring-Pipeline-Orchestration"

Why I chose 3-hour intervals:

    Original plan: Every 5 minutes = 103,680 transitions/month (exceeds FREE tier)
    Optimized plan: Every 3 hours = 2,880 transitions/month (within FREE tier)
    Cost savings: 99% reduction ($2.00/month â†’ $0.02/month)
    Still effective: 8 data points per day provides adequate monitoring coverage

Parallel Processing Implementation
Why I Implemented Parallel Processing

Performance improvement I achieved:

    Sequential approach: 4 metrics Ã— 750ms = 3,000ms total
    Parallel approach: All 4 metrics simultaneously = 917ms total
    Speed improvement: 3.3x faster âš¡

Benefits I gained:

    Faster execution - Complete data collection in under 1 second
    Better scalability - Can add more metric types without increasing total time
    Fault isolation - One branch failure doesn't break entire pipeline
    Cost efficiency - Faster execution reduces Step Functions state time

How I Verified Parallel Execution

Date: February 19, 2026 - 11:27:42 UTC

I tested the parallel execution and verified in CloudWatch Logs:

11:27:42.381 - START: CollectNetworkMetrics (i-218570)
11:27:43.090 - START: CollectCPUMetrics (i-640001)
11:27:43.113 - START: CollectDiskMetrics (i-987770)
11:27:43.298 - START: CollectMemoryMetrics (i-449472)

What I observed: âœ… All 4 Lambda invocations started within 917ms âœ… Each branch processed a different metric type âœ… Separate S3 files created with metric type in filename âœ… All DynamoDB writes successful âœ… All CloudWatch metrics published âœ… Different instance IDs per branch (as designed)
Error Handling & Retry Logic
Retry Configuration I Implemented

I configured retry logic for each branch with exponential backoff:

"Retry": [
  {
    "ErrorEquals": ["States.TaskFailed"],
    "IntervalSeconds": 10,
    "MaxAttempts": 3,
    "BackoffRate": 2
  }
]

How it works:

    Attempt 1: Immediate execution
    Attempt 2: Wait 10 seconds (if failed)
    Attempt 3: Wait 20 seconds (if failed again)
    Attempt 4: Wait 40 seconds (if failed again)
    After 3 retries: Move to failure state

Error Handling Strategy I Designed

Individual Branch Failures: I implemented graceful degradation where if one metric collection fails, the others continue:

"Catch": [
  {
    "ErrorEquals": ["States.ALL"],
    "ResultPath": "$.cpu_error",
    "Next": "CPUCollectionFailed"
  }
]

Why I did this:

    Partial data is better than no data
    One metric failure shouldn't break entire pipeline
    Other metrics can still be collected and analyzed

Complete Pipeline Failure: I added a catch-all error handler at the parallel state level:

"Catch": [
  {
    "ErrorEquals": ["States.ALL"],
    "ResultPath": "$.error",
    "Next": "HandleError"
  }
]

This sends an SNS notification with error details and marks the execution as FAILED.
Performance Analysis
Execution Results I Achieved

Parallel Data Collection Phase:

    Start: 11:27:42.381 UTC
    End: 11:27:43.298 UTC
    Duration: 917ms

Individual Branch Performance:
Network Traffic
	
762ms
	
âœ… Success
CPU Utilization
	
~580ms
	
âœ… Success
Disk Usage
	
~580ms
	
âœ… Success
Memory Usage
	
~580ms
	
âœ… Success

Total Step Functions Execution:

    ParallelDataCollection: ~917ms
    WaitForProcessing: 5,000ms
    CheckPipelineHealth: ~50ms
    ParallelAnalytics: ~100ms
    NotifySuccess: ~200ms
    Total: ~6.3 seconds

Performance Comparison
Data Collection
	
3,000ms
	
917ms
	
3.3x faster
Total Execution
	
~8 seconds
	
~6.3 seconds
	
21% faster
Throughput
	
1 metric/750ms
	
4 metrics/917ms
	
4.4x better
Cost Analysis
How I Optimized for AWS Free Tier

State Transitions per Execution: I calculated that each execution uses 12 state transitions:

    ExecutionStarted â†’ ParallelDataCollection: 1
    ParallelDataCollection â†’ 4 branches: 4
    4 branches complete: 4
    WaitForProcessing: 1
    CheckPipelineHealth: 1
    ParallelAnalytics â†’ 2 branches: 2
    2 branches complete: 2
    NotifySuccess: 1

Monthly Usage:

    Executions per day: 8 (every 3 hours)
    Monthly executions: 240
    Total transitions: 240 Ã— 12 = 2,880/month
    FREE tier limit: 4,000/month
    Usage: 72% of FREE tier âœ…

Complete Cost Breakdown
Step Functions
	
2,880 transitions
	
4,000/month
	
$0.00
Lambda
	
960 invocations
	
1M/month
	
$0.00
S3
	
960 files (~20MB)
	
5GB/month
	
$0.01
DynamoDB
	
960 writes
	
25GB storage
	
$0.00
CloudWatch
	
Logs + Metrics
	
Always Free
	
$0.00
SNS
	
240 emails
	
1,000/month
	
$0.00
EventBridge
	
240 triggers
	
Always Free
	
$0.00
Athena
	
Minimal queries
	
1TB/month
	
$0.01
Total
	
	
	
~$0.02/month

Cost optimization I achieved:

    Original estimate: $2.00/month
    Final cost: $0.02/month
    Savings: 99% ðŸŽ‰

Testing & Verification
Test 1: Parallel Execution Verification

Date: February 19, 2026 - 11:27:42 UTC

I executed the state machine and verified parallel processing:

Results: âœ… All 4 Lambda invocations started within 917ms âœ… Each branch processed different metric type âœ… Separate S3 files created: metrics-cpu_utilization-*.json, metrics-memory_usage-*.json, etc. âœ… All DynamoDB writes successful (4 records) âœ… All CloudWatch metrics published (4 data points) âœ… SNS success notification received
Test 2: Error Handling Verification

I tested the retry logic by simulating a Lambda failure:

Results: âœ… Failed branch retried 3 times (10s, 20s, 40s intervals) âœ… After 3 retries, moved to failure state âœ… Other branches continued successfully âœ… Pipeline completed with partial data âœ… No complete failure (graceful degradation worked)
Test 3: End-to-End Workflow

I verified the complete pipeline from EventBridge trigger to SNS notification:

Execution Flow:

    âœ… EventBridge triggered Step Functions at scheduled time
    âœ… ParallelDataCollection executed 4 Lambda invocations
    âœ… All metrics written to S3 (4 separate files)
    âœ… All metrics written to DynamoDB (4 records)
    âœ… All metrics published to CloudWatch (4 data points)
    âœ… S3 event triggered log-processor Lambda
    âœ… WaitForProcessing completed (5 seconds)
    âœ… CheckPipelineHealth passed
    âœ… ParallelAnalytics executed (2 branches)
    âœ… NotifySuccess sent SNS email
    âœ… Execution marked as SUCCEEDED

Total Execution Time: 6.3 seconds
Status: âœ… PASSED
Deliverables Completed
âœ… Step Functions State Machine Created

    Name: InfraMonitoring-Pipeline-Orchestration
    Type: Standard workflow
    States: 15 total (including error handling states)
    Parallel branches: 6 total (4 for data collection, 2 for analytics)

âœ… Workflow JSON Definition Documented

    Complete state machine definition saved to state-machine.json
    Includes all retry policies and error handling
    Version controlled in project repository

âœ… Error Handling Configured

    Individual branch retry logic (3 attempts, exponential backoff)
    Graceful failure states for each metric type
    Global error handler with SNS notifications
    Fail state for complete pipeline failures

âœ… Parallel Processing Implemented

    4 simultaneous Lambda invocations for metric collection
    3.3x performance improvement over sequential approach
    Separate S3 files per metric type
    Independent error handling per branch

âœ… EventBridge Integration Complete

    Schedule: Every 3 hours (8 executions/day)
    Monthly executions: 240
    Stays within FREE tier (2,880 transitions vs 4,000 limit)

âœ… Execution Logs Verified

    CloudWatch Logs show parallel invocations
    Step Functions execution history accessible
    All state transitions logged
    Performance metrics captured

Key Learnings
Technical Insights I Gained

1. Parallel Processing is Powerful I learned that parallel processing provides significant performance improvements (3.3x faster) with minimal code changes. This pattern is essential for production-grade data pipelines.

2. Error Handling is Critical I discovered that individual branch failures shouldn't break the entire pipeline. Implementing retry logic with exponential backoff prevents transient failures, and partial data collection is better than complete failure.

3. Cost Optimization Matters I realized that small scheduling changes (3-hour vs 5-minute intervals) can result in massive cost reductions (99% savings). Always calculate state transitions before deploying to production.

4. Step Functions Simplifies Orchestration I found that Step Functions' visual workflow representation aids debugging significantly. Built-in retry and error handling reduces custom code, and execution history provides a complete audit trail.
Best Practices I Followed

1. Design for Failure

    Every state has error handling
    Used Catch blocks for graceful degradation
    Always send notifications on failures

2. Optimize for Cost

    Calculated monthly usage before deployment
    Used EventBridge schedules wisely
    Monitored state transitions in CloudWatch

3. Test Thoroughly

    Tested parallel execution with real data
    Simulated failures to verify error handling
    Verified end-to-end workflow multiple times

4. Document Everything

    State machine JSON is version controlled
    Documented retry policies and error handling
    Maintained execution logs for troubleshooting

Challenges I Overcame
Challenge 1: Lambda Function Modification

Problem: My existing Lambda collected all metrics together, not individually.

Solution: I added metric_type parameter support while maintaining backward compatibility. The function now accepts an optional parameter and defaults to collecting all metrics if none is provided.
Challenge 2: State Transition Limits

Problem: My initial 5-minute schedule would exceed the FREE tier (103,680 transitions/month).

Solution: I changed to a 3-hour schedule, reducing transitions to 2,880/month (72% of FREE tier). This still provides adequate monitoring coverage with 8 data points per day.
Challenge 3: Error Handling Complexity

Problem: Needed to handle individual branch failures without breaking the entire pipeline.

Solution: I implemented separate Catch blocks for each branch with failure states, allowing partial success. The pipeline continues even if one metric collection fails.
Challenge 4: Testing Parallel Execution

Problem: Difficult to verify that all branches execute simultaneously.

Solution: I used CloudWatch Logs timestamps to confirm all 4 Lambda invocations started within 917ms. I also verified separate S3 files were created with different instance IDs.
Screenshots Reference

I captured the following screenshots for documentation:

    State Machine Visual Workflow (screenshots/phase10-step-functions/state-machine-parallel-execution.png)
        Shows all 4 parallel branches with green checkmarks
        Complete workflow from start to end

    Execution Event History (screenshots/phase10-step-functions/execution-event-history.png)
        Parallel state transitions
        TaskStateEntered and TaskStateSucceeded events

    CloudWatch Logs - Parallel Invocations (screenshots/phase10-step-functions/cloudwatch-parallel-invocations.png)
        4 simultaneous Lambda invocations
        Different metric types logged

    S3 Bucket - Separate Metric Files (screenshots/phase10-step-functions/s3-parallel-metric-files.png)
        4 separate JSON files with metric type in filename

    EventBridge Schedule Configuration (screenshots/phase10-step-functions/eventbridge-schedule-3hours.png)
        Rate expression: rate(3 hours)

    SNS Success Notification (screenshots/phase10-step-functions/sns-success-email.png)
        Email confirmation of successful execution

Conclusion

I successfully completed Phase 10, the final phase of my Infrastructure Monitoring Pipeline project. This phase demonstrated advanced AWS orchestration capabilities with:

    âœ… Parallel processing for 3.3x performance improvement
    âœ… Robust error handling with retry logic and graceful degradation
    âœ… Cost optimization staying within AWS Free Tier (99% cost reduction)
    âœ… Complete automation with EventBridge scheduling
    âœ… Production-ready workflow with comprehensive logging and notifications

Project Status: ðŸŽ‰ 100% COMPLETE

Total Project Duration: January 27 - February 19, 2026 (24 days)

Final Monthly Cost: ~$0.02 (well under $2 budget)

This project showcases my ability to design and implement production-grade serverless architectures on AWS, with a focus on performance, cost optimization, and operational excellence.